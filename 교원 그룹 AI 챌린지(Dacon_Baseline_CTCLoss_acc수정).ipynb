{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-iFtNJlliPifQG41nP8rV8BaptU4Medn","timestamp":1672379442910},{"file_id":"1iYFwot54TZqJuP1esah43AKCVD6mfUFm","timestamp":1672301950926}],"machine_shape":"hm","authorship_tag":"ABX9TyPJ6BcaHBgtdj1YxDfh7Czu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9720f7a80b0a45a0a635aa16ba46f015":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5c3a6d70242433d96d0b5428a2e5443","IPY_MODEL_91f9f075f62a435186b8851f280e3937","IPY_MODEL_4d2f651735114fbb84cc711e042c86de"],"layout":"IPY_MODEL_006d0a7e9992474fa9bd2aed5b933fb7"}},"e5c3a6d70242433d96d0b5428a2e5443":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48d9f44f561b4b26afefbe0fe8ba7214","placeholder":"​","style":"IPY_MODEL_294ce945a3004f1a958e9a13889f150b","value":"Epoch 15:   2%"}},"91f9f075f62a435186b8851f280e3937":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d33b45dff524e33ae6e2fdeada381d7","max":301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c6d5ed85ad64106bf836bdc980dc797","value":5}},"4d2f651735114fbb84cc711e042c86de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_570baaa5c211480abd3727ea81d99af2","placeholder":"​","style":"IPY_MODEL_521a9e7136944be8acb1dcff1acbd3c9","value":" 5/301 [00:11&lt;11:13,  2.27s/it, loss=0.05, v_num=8, train_loss=0.0428, train_acc=0.992]"}},"006d0a7e9992474fa9bd2aed5b933fb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"48d9f44f561b4b26afefbe0fe8ba7214":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"294ce945a3004f1a958e9a13889f150b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d33b45dff524e33ae6e2fdeada381d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c6d5ed85ad64106bf836bdc980dc797":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"570baaa5c211480abd3727ea81d99af2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"521a9e7136944be8acb1dcff1acbd3c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install pytorch_lightning\n","!pip install timm\n","!pip install einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsz1GWS9oidH","executionInfo":{"status":"ok","timestamp":1672397818917,"user_tz":-540,"elapsed":10074,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"f4b1c916-1bd1-495a-92d8-42853ee142c6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.8/dist-packages (1.8.6)\n","Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2.5.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.11.0)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.13.0+cu116)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.5.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.4.0)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: timm in /usr/local/lib/python3.8/dist-packages (0.6.12)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.0+cu116)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from timm) (0.11.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.8.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"]}]},{"cell_type":"markdown","source":["## 라이브러리 호출\n","\n","학습에 필요한 라이브러리르 호출한다."],"metadata":{"id":"Sm3W9SrvzVKg"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"iNNU3mKPU21p","executionInfo":{"status":"ok","timestamp":1672397822753,"user_tz":-540,"elapsed":3838,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"outputs":[],"source":["import timm\n","import random\n","import os\n","\n","import pandas as pd\n","import numpy as np\n","\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import pytorch_lightning as pl\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.models import resnet18\n","from torchvision import transforms\n","\n","import albumentations as A\n","import albumentations.pytorch\n","\n","from tqdm.auto import tqdm\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedKFold\n","\n","from einops import rearrange, reduce, repeat\n","\n","import gc\n","\n","import warnings\n","warnings.filterwarnings(action='ignore') "]},{"cell_type":"markdown","source":["## 구글 드라이브 연결\n","\n","구글 코랩에서 학습을 수행하기 위해서는 기본적으로 코랩에 연결시켜야 한다. 아래와 같이 수행하면 된다."],"metadata":{"id":"VF6jaIhVzY7_"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDQSlC3QcsXN","executionInfo":{"status":"ok","timestamp":1672397825173,"user_tz":-540,"elapsed":2422,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"6e9b81cc-06f3-43e9-880b-211b51204884"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# !unzip \"/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/datasets/open.zip\""],"metadata":{"id":"PCGE4Yhq8Fw8","executionInfo":{"status":"ok","timestamp":1672397825173,"user_tz":-540,"elapsed":4,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 시드값 고정\n","\n","아래와 같이 시드값을 고정해야지 매번 학습할 때 마다 동일한 결과를 얻을 수 있다. 시드 값은 하고 싶은 숫자를 하면 되고 저는 생일로 하였습니다 😊."],"metadata":{"id":"e5-Acasuzfdv"}},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(428)"],"metadata":{"id":"LXooPSrbdKlW","executionInfo":{"status":"ok","timestamp":1672397825173,"user_tz":-540,"elapsed":4,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## 학습 데이터를 불러옴\n","\n","수정"],"metadata":{"id":"JdNd5ww0zswe"}},{"cell_type":"code","source":["train_df = pd.read_csv('train.csv')"],"metadata":{"id":"tLHYBpd5VGR3","executionInfo":{"status":"ok","timestamp":1672397825174,"user_tz":-540,"elapsed":5,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 학습 데이터로부터 단어 사전(Vocabulary) 구축\n","train_gt = [gt for gt in train_df['label']]\n","train_gt = \"\".join(train_gt)\n","letters = sorted(list(set(list(train_gt))))\n","print(len(letters))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jRT2dZzvVGdv","executionInfo":{"status":"ok","timestamp":1672397825174,"user_tz":-540,"elapsed":4,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"74d2afb4-8eb1-4785-9a14-e117b09d7b02"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2349\n"]}]},{"cell_type":"code","source":["vocabulary = [\"-\"] + letters\n","print(len(vocabulary))\n","idx2char = {k:v for k,v in enumerate(vocabulary, start=0)}\n","char2idx = {v:k for k,v in idx2char.items()}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cV6hccHsVGgm","executionInfo":{"status":"ok","timestamp":1672397825174,"user_tz":-540,"elapsed":3,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"a499bb1f-b28e-41fc-e7c0-94a7731b0d2f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2350\n"]}]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"WGZkqhy_VGln","executionInfo":{"status":"ok","timestamp":1672397826003,"user_tz":-540,"elapsed":6,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"66360475-0cab-4ca9-9a25-0450ecbb1445"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            id                 img_path label\n","0  TRAIN_00000  ./train/TRAIN_00000.png   빨간색\n","1  TRAIN_00001  ./train/TRAIN_00001.png     머\n","2  TRAIN_00002  ./train/TRAIN_00002.png    차차\n","3  TRAIN_00003  ./train/TRAIN_00003.png     써\n","4  TRAIN_00004  ./train/TRAIN_00004.png   놓치다"],"text/html":["\n","  <div id=\"df-f4bfd017-469b-4061-a9b5-0acd7b8b0866\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>img_path</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_00000</td>\n","      <td>./train/TRAIN_00000.png</td>\n","      <td>빨간색</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_00001</td>\n","      <td>./train/TRAIN_00001.png</td>\n","      <td>머</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_00002</td>\n","      <td>./train/TRAIN_00002.png</td>\n","      <td>차차</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_00003</td>\n","      <td>./train/TRAIN_00003.png</td>\n","      <td>써</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_00004</td>\n","      <td>./train/TRAIN_00004.png</td>\n","      <td>놓치다</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4bfd017-469b-4061-a9b5-0acd7b8b0866')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f4bfd017-469b-4061-a9b5-0acd7b8b0866 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f4bfd017-469b-4061-a9b5-0acd7b8b0866');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["train_df['label_len'] = train_df['label'].apply(lambda x: len(x))"],"metadata":{"id":"dfqorXkhVGoX","executionInfo":{"status":"ok","timestamp":1672397826003,"user_tz":-540,"elapsed":5,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"-DCm5Y4MzT6I","executionInfo":{"status":"ok","timestamp":1672397826003,"user_tz":-540,"elapsed":5,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"7a70f8fe-02d9-42a6-b665-e05a381a8db6"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            id                 img_path label  label_len\n","0  TRAIN_00000  ./train/TRAIN_00000.png   빨간색          3\n","1  TRAIN_00001  ./train/TRAIN_00001.png     머          1\n","2  TRAIN_00002  ./train/TRAIN_00002.png    차차          2\n","3  TRAIN_00003  ./train/TRAIN_00003.png     써          1\n","4  TRAIN_00004  ./train/TRAIN_00004.png   놓치다          3"],"text/html":["\n","  <div id=\"df-34db2b54-1667-49e5-9b68-23cbea980745\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>img_path</th>\n","      <th>label</th>\n","      <th>label_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_00000</td>\n","      <td>./train/TRAIN_00000.png</td>\n","      <td>빨간색</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_00001</td>\n","      <td>./train/TRAIN_00001.png</td>\n","      <td>머</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_00002</td>\n","      <td>./train/TRAIN_00002.png</td>\n","      <td>차차</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_00003</td>\n","      <td>./train/TRAIN_00003.png</td>\n","      <td>써</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_00004</td>\n","      <td>./train/TRAIN_00004.png</td>\n","      <td>놓치다</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34db2b54-1667-49e5-9b68-23cbea980745')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-34db2b54-1667-49e5-9b68-23cbea980745 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-34db2b54-1667-49e5-9b68-23cbea980745');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import torchmetrics"],"metadata":{"id":"ZVBQRytdMXHU","executionInfo":{"status":"ok","timestamp":1672397826004,"user_tz":-540,"elapsed":6,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from torch.nn.utils.rnn import pad_sequence\n","\n","transform_train = A.Compose(\n","    [\n","        # A.RandomResizedCrop(\n","        #     height=128, \n","        #     width=256, \n","        #     scale=(0.24, 0.26),\n","        #     ratio=(0.90, 1.10),\n","        #     always_apply=True\n","        #     ),\n","        A.Resize(128, 256),\n","        A.VerticalFlip(p=0.1),\n","        albumentations.OneOf([\n","                            albumentations.MotionBlur(p=0.1),\n","                            albumentations.OpticalDistortion(p=0.3),\n","                            albumentations.GaussNoise(p=0.5)                 \n","        ], p=0.8),\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        A.pytorch.transforms.ToTensorV2()\n","        ])\n","\n","transform_test = A.Compose(\n","    [\n","        A.Resize(128, 256),\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        A.pytorch.transforms.ToTensorV2()\n","        ])\n","\n","\"\"\"\n","    지금에서야 깨달음\n","    Collator로 넘어오기 전에 Dataset에서 처리가 다 끝나고 batch_size 만큼\n","    리스트로해서 Collator에게 넘겨주네 ...\n","    그러니 DataLoader에서 너가 선택한 batch_size 만큼 수정을 해줘야함.\n","\"\"\"\n","class TextCollator():\n","    def __init__(self, is_train = False):\n","        self.is_train = is_train\n","    \n","    def __call__(self, samples):\n","        if self.is_train:\n","            return_image = []\n","            return_label = []\n","            for i in range(len(samples)):\n","                image, label = samples[i]\n","                return_image.append(image.unsqueeze(0))\n","                return_label.append(torch.LongTensor([char2idx[x] for x in label] + [2]))\n","            return_image = torch.vstack(return_image)\n","            return_label = pad_sequence(return_label, batch_first = True)\n","            return_label = torch.LongTensor(return_label)\n","            return return_image, return_label\n","        else:\n","            return_image = []\n","            for i in range(len(samples)):\n","                image = samples[i]\n","                return_image.append(image.unsqueeze(0))\n","            return_image = torch.vstack(return_image)\n","            return return_image\n","\n","class TextDataset(Dataset):\n","    def __init__(self, images, labels = None, is_train = False, is_valid = False):\n","        self.images = images\n","        self.labels = labels\n","        self.is_train = is_train\n","        self.is_valid = is_valid\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    \"\"\"\n","        is_train : 학습에서는 이미지 변경을 수행해주는 작업이 필요하기 때문에\n","        학습 중이라는 별도의 표시가 필요함\n","        is_valid : 학습에서는 이미지 변경이 필요하지만 검증에서는 불필요 하기\n","        때문에 별도로 빼서 진행\n","    \"\"\"\n","    def __getitem__(self, idx):\n","        image_path = self.images[idx]\n","        if self.is_train or self.is_valid:\n","            label = self.labels[idx]\n","        temp = Image.open(image_path).convert(\"RGB\")\n","        image = np.array(temp).copy()\n","        temp.close()\n","\n","        if self.is_train:\n","            # 학습 데이터\n","            transformed = transform_train(image = image)\n","            image = transformed['image']\n","            return (image, label)\n","        elif self.is_valid:\n","            # 검증 데이터 \n","            transformed = transform_test(image = image)\n","            image = transformed['image']\n","            return (image, label)\n","        else:\n","            # 테스트 데이터\n","            transformed = transform_test(image = image)\n","            image = transformed['image']\n","            return image"],"metadata":{"id":"S1IbhRq1VGqW","executionInfo":{"status":"ok","timestamp":1672397826004,"user_tz":-540,"elapsed":6,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["config = {\n","    'n_splits' : 5,\n","    'random_seed' : 428,\n","    'batch_size' : 256,\n","    'input_size' : 1024,\n","    'hidden_size' : 1024,\n","    'num_layers' : 1,\n","    'dropout' : 0.1,\n","    'model' : 'regnetx_032',\n","    'vocabulary_len' : len(vocabulary),\n","    'accumulate_grad_batches' : 1,\n","    'patience' : 40,\n","    'max_epochs' : 300\n","}"],"metadata":{"id":"WYRJ8sjHBE0L","executionInfo":{"status":"ok","timestamp":1672397826004,"user_tz":-540,"elapsed":5,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# eff = timm.create_model(config['model'], pretrained=True)\n","# # CNN Feature Extract\n","# eff = list(eff.children())[:-2]\n","# feature_extract = nn.Sequential(\n","#     *eff\n","# )\n","# train_dataset = TextDataset(train_df['img_path'].reset_index(drop=True), train_df['label'].reset_index(drop=True), is_train = True)\n","# images, labels = train_dataset[0]\n","# feature_extract(images.unsqueeze(0)).shape"],"metadata":{"id":"4boHj5icJBOo","executionInfo":{"status":"ok","timestamp":1672397826004,"user_tz":-540,"elapsed":5,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# assert False"],"metadata":{"id":"vh4hZn0yIDaz","executionInfo":{"status":"ok","timestamp":1672397826004,"user_tz":-540,"elapsed":5,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from pytorch_lightning.accelerators import accelerator\n","class OCRModel(pl.LightningModule):\n","    def __init__(self, config):\n","        # Regnetx_006 -> torch.Size([1, 528, 4, 8]) [:-2]\n","        # Regnetx_032 -> torch.Size([1, 1008, 4, 8]) [:-2]\n","        # Effnet -> # torch.Size([2, 512, 4, 8]) [:-4]\n","        super().__init__()\n","        self.config = config\n","        eff =  timm.create_model(config['model'], pretrained=True)\n","        self.eff_feature_extract = nn.Sequential(*list(eff.children())[:-2]) \n","        self.eff_linear = nn.Sequential(\n","            # nn.BatchNorm1d(8),\n","            nn.Linear(1008 * 4, 1024, bias = False),\n","            # nn.BatchNorm1d(8),\n","        )\n","        # -> batch_size x 7 x (640 * 2)\n","        \n","        self.lstm = nn.LSTM(input_size = config['input_size'], # input_size = 512\n","                            hidden_size = config['hidden_size'], #  hiddden_size = 512\n","                            num_layers = config['num_layers'],  # num_laters \n","                            dropout = config['dropout'], # dropout\n","                            bidirectional = True,\n","                            batch_first = True)\n","        \n","        self.lstm_linear = nn.Linear(config['hidden_size']*2, config['vocabulary_len'])\n","\n","        loss_weight = torch.ones(config['vocabulary_len'])\n","        loss_weight[0] = 0\n","\n","        self.crit = nn.CrossEntropyLoss(\n","            weight = loss_weight\n","        )\n","        self.criterion = nn.CTCLoss(blank=0) # idx 0 : -\n","\n","    def forward(self, x):\n","        images = x\n","\n","        representation = self.eff_feature_extract(images)\n","        # |representation| = (batch_size, 640, 2, 7) = (batch_size, channel, height, width)\n","        representation = representation.permute(0, 3, 1, 2)\n","        representation = rearrange(representation, 'b w c h -> b w (c h)')\n","        # |representation| = (batch_size, 7, 1280) = (batch_size, width, (channel * height))\n","        representation = self.eff_linear(representation)\n","        # |representation| = (batch_size, 7, 512)\n","\n","        context, _ = self.lstm(representation)\n","        # |conext| = (batch_size, 7, 512 * 2)\n","        context = self.lstm_linear(context)\n","        # |context| = (batch_size, 7, vocabulary_len)\n","\n","        context = rearrange(context, 'b t v -> t b v')\n","\n","        return context\n","\n","    # 샘플 별 추론결과를 독립적으로 후처리\n","    def remove_duplicates(self, text):\n","        if len(text) > 1:\n","            letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n","        elif len(text) == 1:\n","            letters = [text[0]]\n","        else:\n","            return \"\"\n","        return \"\".join(letters)\n","\n","    def correct_prediction(self, word):\n","        parts = word.split(\"-\")\n","        parts = [self.remove_duplicates(part) for part in parts]\n","        corrected_word = \"\".join(parts)\n","        return corrected_word\n","\n","    def get_acc(self, text_batch_logits, labels):\n","        # acc구할 차례\n","        text_batch_logits = text_batch_logits.permute(1, 0, 2)\n","        text_batch_logits_argmax = text_batch_logits.argmax(dim = -1)\n","        # |text_batch_logits_argmax| = (batch_size, T)\n","\n","        text_batch_tokens_new = []\n","        for text_tokens in text_batch_logits_argmax:\n","            text = [idx2char[int(idx)] for idx in text_tokens]\n","            text = \"\".join(text)\n","            text_batch_tokens_new.append(text)\n","\n","        temp = pd.DataFrame(text_batch_tokens_new, columns = ['label'])\n","        temp['label'] = temp['label'].apply(self.correct_prediction)\n","\n","        # print(temp['label'][:10], labels[:10])\n","        acc = accuracy_score(temp['label'].values, labels)\n","        \n","        del temp\n","        gc.collect()\n","\n","        return acc\n","\n","    def encode_text_batch(self, text_batch):\n","        text_batch_targets_lens = [len(text) for text in text_batch]\n","        text_batch_targets_lens = torch.IntTensor(text_batch_targets_lens)\n","\n","        text_batch_concat = \"\".join(text_batch)\n","        text_batch_targets = [char2idx[c] for c in text_batch_concat]\n","        text_batch_targets = torch.IntTensor(text_batch_targets)\n","        \n","        return text_batch_targets, text_batch_targets_lens\n","\n","    def compute_loss(self, text_batch, text_batch_logits): # labels, context\n","        \"\"\"\n","        text_batch: list of strings of length equal to batch size\n","        text_batch_logits: Tensor of size([T, batch_size, num_classes])\n","        \"\"\"\n","        text_batch_logps = F.log_softmax(text_batch_logits, 2) # [T, batch_size, num_classes]  \n","        text_batch_logps_lens = torch.full(size=(text_batch_logps.size(1),), \n","                                        fill_value=text_batch_logps.size(0), \n","                                        dtype=torch.int32).to(text_batch_logits.device) # [batch_size] \n","\n","        text_batch_targets, text_batch_targets_lens = self.encode_text_batch(text_batch)\n","\n","        loss = self.criterion(text_batch_logps, text_batch_targets, text_batch_logps_lens, text_batch_targets_lens)\n","\n","        # acc구할 차례\n","        acc = self.get_acc(text_batch_logits, text_batch)\n","\n","        return loss, acc\n","\n","    def training_step(self, batch, batch_idx):\n","        # batch = (image, label)\n","        # |image| = (batch_size, channel, h, w)\n","        # |label| = (\"안녕하세요\", \"나는\") <- tuple 형태로 담겨져 있음\n","        images, labels = batch\n","\n","        representation = self.eff_feature_extract(images)\n","        # |representation| = (batch_size, 512, 4, 8) = (batch_size, channel, height, width)\n","        representation = representation.permute(0, 3, 1, 2)\n","        representation = rearrange(representation, 'b w c h -> b w (c h)')\n","        # |representation| = (batch_size, 8, 512*4) = (batch_size, width, (channel * height))\n","        representation = self.eff_linear(representation)\n","        # |representation| = (batch_size, 8, 512)\n","\n","        context, _ = self.lstm(representation)\n","        # |conext| = (batch_size, 7, 512 * 2)\n","        context = self.lstm_linear(context)\n","        # |context| = (batch_size, 7, vocabulary_len)\n","\n","        context = rearrange(context, 'b t v -> t b v')\n","        \n","        loss, acc = self.compute_loss(labels, context)\n","\n","\n","        metrics = {'train_loss':loss, 'train_acc':acc}\n","        self.log_dict(metrics, prog_bar=True)\n","        return {\n","            \"loss\":loss\n","        }\n","\n","    def validation_step(self, batch, batch_idx):\n","        # batch = (image, label)\n","        # |image| = (batch_size, channel, h, w)\n","        # |label| = (batch_size, length) 여기서 length의 최대 길이를 7로 설정함 \n","        images, labels = batch\n","\n","        representation = self.eff_feature_extract(images)\n","        # |representation| = (batch_size, 640, 2, 7) = (batch_size, channel, height, width)\n","        representation = representation.permute(0, 3, 1, 2)\n","        representation = rearrange(representation, 'b w c h -> b w (c h)')\n","        # |representation| = (batch_size, 7, 1280) = (batch_size, width, (channel * height))\n","        representation = self.eff_linear(representation)\n","        # |representation| = (batch_size, 7, 512)\n","\n","        context, _ = self.lstm(representation)\n","        # |conext| = (batch_size, 7, 512 * 2)\n","        context = self.lstm_linear(context)\n","        # |context| = (batch_size, 7, vocabulary_len)\n","\n","        context = rearrange(context, 'b t v -> t b v')\n","        \n","        loss, acc = self.compute_loss(labels, context)\n","\n","\n","        metrics = {'val_loss':loss, 'val_acc': acc}\n","        self.log_dict(metrics, prog_bar=True)\n","        return {\n","            \"loss\":loss\n","        }\n","\n","    def test_step(self, batch, batch_idx):\n","        pass\n","    \n","    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n","        images = batch\n","\n","        representation = self.eff_feature_extract(images)\n","        # |representation| = (batch_size, 640, 2, 7) = (batch_size, channel, height, width)\n","        representation = representation.permute(0, 3, 1, 2)\n","        representation = rearrange(representation, 'b w c h -> b w (c h)')\n","        # |representation| = (batch_size, 7, 1280) = (batch_size, width, (channel * height))\n","        representation = self.eff_linear(representation)\n","        # |representation| = (batch_size, 7, 512)\n","\n","        context, _ = self.lstm(representation)\n","        # |conext| = (batch_size, 7, 512 * 2)\n","        context = self.lstm_linear(context)\n","        # |context| = (batch_size, 7, vocabulary_len)\n","\n","        context = rearrange(context, 'b t v -> t b v')\n","\n","        return context\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n","        return optimizer"],"metadata":{"id":"4aG0E8jg1bcR","executionInfo":{"status":"ok","timestamp":1672397826005,"user_tz":-540,"elapsed":6,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## loc으로 꺼내온 데이터 에는 reset_index를 해줘야함\n","\n","reset_index 해줘야 하는거 모르고 개고생했네 ...."],"metadata":{"id":"alKgaFlTn13C"}},{"cell_type":"code","source":["from pytorch_lightning.callbacks import RichProgressBar, EarlyStopping, ModelCheckpoint\n","\n","train_dataset = TextDataset(train_df['img_path'].reset_index(drop=True), train_df['label'].reset_index(drop=True), is_train = True)\n","train_dataloader = DataLoader(train_dataset, batch_size = config['batch_size'], shuffle = True)\n","\n","dirpath = f\"/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold\"\n","checkpoint_callback = ModelCheckpoint(\n","dirpath=dirpath,\n","save_last = True,\n","save_top_k =-1,\n","filename='{epoch}-{step}-{train_loss:.4f}-{train_acc:.4f}',\n","verbose=True,\n","monitor='train_acc',\n","mode='max'\n",")\n","\n","model = OCRModel(config)\n","trainer = pl.Trainer(max_epochs = config['max_epochs'], accelerator=\"gpu\", accumulate_grad_batches = config['accumulate_grad_batches'], precision=16,\n","                        callbacks=[EarlyStopping('train_acc', patience = config['patience'], mode='max', verbose = True), checkpoint_callback])\n","\n","trainer.fit(model, train_dataloader)\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":914,"referenced_widgets":["9720f7a80b0a45a0a635aa16ba46f015","e5c3a6d70242433d96d0b5428a2e5443","91f9f075f62a435186b8851f280e3937","4d2f651735114fbb84cc711e042c86de","006d0a7e9992474fa9bd2aed5b933fb7","48d9f44f561b4b26afefbe0fe8ba7214","294ce945a3004f1a958e9a13889f150b","9d33b45dff524e33ae6e2fdeada381d7","1c6d5ed85ad64106bf836bdc980dc797","570baaa5c211480abd3727ea81d99af2","521a9e7136944be8acb1dcff1acbd3c9"]},"id":"IvE4sVOqulSF","executionInfo":{"status":"ok","timestamp":1672407888520,"user_tz":-540,"elapsed":10062521,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"aa66fb37-0b46-4161-8beb-51dd968ed3a1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name                | Type             | Params\n","---------------------------------------------------------\n","0 | eff_feature_extract | Sequential       | 14.3 M\n","1 | eff_linear          | Sequential       | 4.1 M \n","2 | lstm                | LSTM             | 16.8 M\n","3 | lstm_linear         | Linear           | 4.8 M \n","4 | crit                | CrossEntropyLoss | 0     \n","5 | criterion           | CTCLoss          | 0     \n","---------------------------------------------------------\n","40.0 M    Trainable params\n","0         Non-trainable params\n","40.0 M    Total params\n","80.050    Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9720f7a80b0a45a0a635aa16ba46f015"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved. New best score: 0.011\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 301: 'train_acc' reached 0.01136 (best 0.01136), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=0-step=301-train_loss=5.3249-train_acc=0.0114.ckpt' as top 1\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.068 >= min_delta = 0.0. New best score: 0.080\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 602: 'train_acc' reached 0.07955 (best 0.07955), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=1-step=602-train_loss=3.7806-train_acc=0.0795.ckpt' as top 2\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.193 >= min_delta = 0.0. New best score: 0.273\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 903: 'train_acc' reached 0.27273 (best 0.27273), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=2-step=903-train_loss=2.2352-train_acc=0.2727.ckpt' as top 3\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.330 >= min_delta = 0.0. New best score: 0.602\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 1204: 'train_acc' reached 0.60227 (best 0.60227), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=3-step=1204-train_loss=1.2841-train_acc=0.6023.ckpt' as top 4\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.102 >= min_delta = 0.0. New best score: 0.705\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 1505: 'train_acc' reached 0.70455 (best 0.70455), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=4-step=1505-train_loss=0.9243-train_acc=0.7045.ckpt' as top 5\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.170 >= min_delta = 0.0. New best score: 0.875\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 1806: 'train_acc' reached 0.87500 (best 0.87500), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=5-step=1806-train_loss=0.5554-train_acc=0.8750.ckpt' as top 6\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.011 >= min_delta = 0.0. New best score: 0.886\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 2107: 'train_acc' reached 0.88636 (best 0.88636), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=6-step=2107-train_loss=0.3505-train_acc=0.8864.ckpt' as top 7\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.023 >= min_delta = 0.0. New best score: 0.909\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 2408: 'train_acc' reached 0.90909 (best 0.90909), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=7-step=2408-train_loss=0.3052-train_acc=0.9091.ckpt' as top 8\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 2709: 'train_acc' reached 0.90909 (best 0.90909), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=8-step=2709-train_loss=0.2330-train_acc=0.9091.ckpt' as top 9\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.045 >= min_delta = 0.0. New best score: 0.955\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 3010: 'train_acc' reached 0.95455 (best 0.95455), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=9-step=3010-train_loss=0.1404-train_acc=0.9545.ckpt' as top 10\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 10, global step 3311: 'train_acc' reached 0.95455 (best 0.95455), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=10-step=3311-train_loss=0.1274-train_acc=0.9545.ckpt' as top 11\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.023 >= min_delta = 0.0. New best score: 0.977\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 11, global step 3612: 'train_acc' reached 0.97727 (best 0.97727), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=11-step=3612-train_loss=0.0905-train_acc=0.9773.ckpt' as top 12\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 12, global step 3913: 'train_acc' reached 0.95455 (best 0.97727), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=12-step=3913-train_loss=0.0914-train_acc=0.9545.ckpt' as top 13\n","INFO:pytorch_lightning.callbacks.early_stopping:Metric train_acc improved by 0.011 >= min_delta = 0.0. New best score: 0.989\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 13, global step 4214: 'train_acc' reached 0.98864 (best 0.98864), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=13-step=4214-train_loss=0.0656-train_acc=0.9886.ckpt' as top 14\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 14, global step 4515: 'train_acc' reached 0.98864 (best 0.98864), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/2023_교원그룹_AI_챌린지/NoFold/epoch=14-step=4515-train_loss=0.0753-train_acc=0.9886.ckpt' as top 15\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Vy2Id6uVYb0-","executionInfo":{"status":"ok","timestamp":1672407888521,"user_tz":-540,"elapsed":9,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z70IGc_QGiIw","executionInfo":{"status":"ok","timestamp":1672407888521,"user_tz":-540,"elapsed":9,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}}},"execution_count":19,"outputs":[]}]}